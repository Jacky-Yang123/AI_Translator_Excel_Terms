import os
import sys
import re
import json
import subprocess
from datetime import datetime

import pandas as pd
import streamlit as st


def find_yt_dlp():
    """æŸ¥æ‰¾yt-dlpå¯æ‰§è¡Œæ–‡ä»¶"""
    if sys.platform.startswith('win'):
        candidates = ["yt-dlp.exe", "yt-dlp"]
    else:
        candidates = ["./yt-dlp", "yt-dlp"]
    
    for candidate in candidates:
        if os.path.exists(candidate):
            return candidate
    return "yt-dlp"


def normalize_url(url):
    """å°†éæ ‡å‡†çš„Niconico URLæ ¼å¼è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼"""
    return url.replace("www.video.nicovideo.jp", "www.nicovideo.jp")


def extract_watch_id(url):
    """ä»Niconicoè§†é¢‘URLä¸­æå–watch ID (sm/nmå·)"""
    match = re.search(r'(sm|nm)\d+', url)
    if match:
        return match.group(0)
    return "unknown_id"


def extract_bilibili_id(url):
    """ä»Bilibiliè§†é¢‘URLä¸­æå–video ID (BVå·æˆ–avå·)"""
    bv_match = re.search(r'BV[a-zA-Z0-9]+', url)
    if bv_match:
        return bv_match.group(0)
    
    av_match = re.search(r'av(\d+)', url)
    if av_match:
        return f"av{av_match.group(1)}"
    
    return "unknown_id"


def run_yt_dlp_to_get_json(url, output_filename_base="danmaku"):
    """è¿è¡Œyt-dlpå‘½ä»¤æ¥æŠ“å–å¼¹å¹•æ•°æ®å¹¶ä¿å­˜ä¸ºJSONæ–‡ä»¶"""
    yt_dlp_path = find_yt_dlp()
    
    command = [
        yt_dlp_path,
        "--skip-download",
        "--write-sub",
        "--all-subs",
        "--sub-format", "json",
        "--output", f"{output_filename_base}.%(ext)s",
        url
    ]
    
    try:
        result = subprocess.run(command, capture_output=True, text=True, check=True)
        
        json_filename = f"{output_filename_base}.comments.json"
        if os.path.exists(json_filename):
            return json_filename
        else:
            return None
            
    except subprocess.CalledProcessError as e:
        st.error(f"yt-dlpæ‰§è¡Œå¤±è´¥: {e.stderr}")
        return None
    except FileNotFoundError:
        st.error(f"æ‰¾ä¸åˆ°yt-dlpå¯æ‰§è¡Œæ–‡ä»¶ã€‚è¯·ç¡®ä¿yt-dlpå·²å®‰è£…æˆ–åœ¨PATHä¸­ã€‚")
        return None


def process_niconico_json_to_dataframe(json_path):
    """è¯»å–yt-dlpç”Ÿæˆçš„JSONæ–‡ä»¶ï¼Œå¤„ç†Niconicoå¼¹å¹•æ•°æ®"""
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError) as e:
        st.error(f"JSONæ–‡ä»¶å¤„ç†å¤±è´¥: {e}")
        return None

    danmaku_list = []
    for comment in data:
        vpos_ms = comment.get("vposMs", 0)
        time_sec = vpos_ms / 1000
        video_time = time.strftime('%H:%M:%S', time.gmtime(time_sec))
        
        posted_at_str = comment.get("postedAt")
        try:
            posted_at = datetime.fromisoformat(posted_at_str)
            send_time = posted_at.strftime('%Y-%m-%d %H:%M:%S')
        except:
            send_time = posted_at_str
            
        commands = " ".join(comment.get("commands", []))
        
        danmaku_info = {
            "å¼¹å¹•å†…å®¹": comment.get("body"),
            "è§†é¢‘æ—¶é—´": video_time,
            "æ—¶é—´(ç§’)": time_sec,
            "æ ¼å¼/é¢œè‰²": commands,
            "ç”¨æˆ·ID": comment.get("userId"),
            "å‘é€æ—¶é—´": send_time,
            "ç¼–å·": comment.get("no"),
        }
        danmaku_list.append(danmaku_info)
        
    if not danmaku_list:
        return None
        
    df = pd.DataFrame(danmaku_list)
    df = df[['ç¼–å·', 'è§†é¢‘æ—¶é—´', 'æ—¶é—´(ç§’)', 'å¼¹å¹•å†…å®¹', 'æ ¼å¼/é¢œè‰²', 'ç”¨æˆ·ID', 'å‘é€æ—¶é—´']]
    return df


def scrape_niconico_danmaku(url):
    """æŠ“å–Niconicoå¼¹å¹•"""
    normalized_url = normalize_url(url)
    watch_id = extract_watch_id(normalized_url)
    
    with st.spinner(f"æ­£åœ¨æŠ“å–Niconicoè§†é¢‘ {watch_id} çš„å¼¹å¹•..."):
        json_path = run_yt_dlp_to_get_json(normalized_url, output_filename_base=watch_id)
        
        if json_path:
            df = process_niconico_json_to_dataframe(json_path)
            
            try:
                os.remove(json_path)
            except OSError:
                pass
            
            return df, watch_id
        else:
            return None, watch_id


def scrape_bilibili_danmaku(url, cookies_file=None):
    """æŠ“å–Bilibiliå¼¹å¹•"""
    video_id = extract_bilibili_id(url)
    
    with st.spinner(f"æ­£åœ¨æŠ“å–Bilibiliè§†é¢‘ {video_id} çš„å¼¹å¹•..."):
        yt_dlp_path = find_yt_dlp()
        
        command = [
            yt_dlp_path,
            "--skip-download",
            "--write-sub",
            "--all-subs",
            "--sub-format", "json",
            "--output", f"{video_id}.%(ext)s",
        ]
        
        if cookies_file and os.path.exists(cookies_file):
            command.extend(["--cookies", cookies_file])
        
        command.append(url)
        
        try:
            result = subprocess.run(command, capture_output=True, text=True, check=True, timeout=60)
            
            json_filename = f"{video_id}.comments.json"
            if os.path.exists(json_filename):
                try:
                    with open(json_filename, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                except (FileNotFoundError, json.JSONDecodeError) as e:
                    st.error(f"JSONæ–‡ä»¶å¤„ç†å¤±è´¥: {e}")
                    return None, video_id
                
                danmaku_list = []
                for comment in data:
                    danmaku_info = {
                        "å¼¹å¹•å†…å®¹": comment.get("body", comment.get("text", "")),
                        "å‘é€æ—¶é—´": comment.get("postedAt", comment.get("timestamp", "")),
                        "ç”¨æˆ·ID": comment.get("userId", comment.get("author", "")),
                    }
                    danmaku_list.append(danmaku_info)
                
                if danmaku_list:
                    df = pd.DataFrame(danmaku_list)
                    
                    try:
                        os.remove(json_filename)
                    except OSError:
                        pass
                    
                    return df, video_id
                else:
                    st.warning("æœªæ‰¾åˆ°å¼¹å¹•æ•°æ®")
                    return None, video_id
            else:
                st.error(f"yt-dlpæœªç”Ÿæˆé¢„æœŸçš„æ–‡ä»¶")
                return None, video_id
                
        except subprocess.CalledProcessError as e:
            error_msg = e.stderr if e.stderr else str(e)
            if "412" in error_msg or "Precondition Failed" in error_msg:
                st.error(
                    "âŒ Bilibili APIé€Ÿç‡é™åˆ¶ï¼ˆHTTP 412é”™è¯¯ï¼‰\n\n"
                    "è¿™é€šå¸¸æ˜¯å› ä¸ºï¼š\n"
                    "1. æ²¡æœ‰æä¾›æœ‰æ•ˆçš„Cookieè®¤è¯\n"
                    "2. è¯¥IPåœ°å€çš„è¯·æ±‚å·²è¾¾åˆ°é™åˆ¶\n\n"
                    "**è§£å†³æ–¹æ¡ˆï¼š**\n"
                    "è¯·åœ¨å·¦ä¾§æ ä¸Šä¼ æ‚¨çš„Bilibili Cookieæ–‡ä»¶ï¼Œç„¶åé‡è¯•ã€‚"
                )
            else:
                st.error(f"yt-dlpæ‰§è¡Œå¤±è´¥: {error_msg}")
            return None, video_id
        except subprocess.TimeoutExpired:
            st.error("âŒ è¯·æ±‚è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•")
            return None, video_id
        except FileNotFoundError:
            st.error(f"æ‰¾ä¸åˆ°yt-dlpå¯æ‰§è¡Œæ–‡ä»¶")
            return None, video_id


def danmu_page():
    st.markdown("""
    # ğŸ¬ å¼¹å¹•æŠ“å–å·¥å…·
    
    æ”¯æŒä» **Niconico** å’Œ **Bilibili** æŠ“å–è§†é¢‘å¼¹å¹•ï¼Œå¹¶å¯¼å‡ºä¸º Excel æ–‡ä»¶ã€‚
    """)
    
    with st.sidebar:
        st.header("âš™ï¸ é…ç½®1")
        platform = st.radio(
            "é€‰æ‹©è§†é¢‘å¹³å°",
            options=["Niconico", "Bilibili"],
            help="é€‰æ‹©æ‚¨è¦æŠ“å–å¼¹å¹•çš„è§†é¢‘å¹³å°",
            key="video_pla_selector"
        )
        
        st.divider()
        
        bilibili_cookies_file = None
        if platform == "Bilibili":
            st.subheader("ğŸ” Bilibili Cookieé…ç½®")
            st.markdown(
                """Bilibiliéœ€è¦Cookieè®¤è¯ä»¥é¿å…é€Ÿç‡é™åˆ¶ã€‚\n\n
                **è·å–Cookieçš„æ–¹æ³•ï¼š**
                1. æ‰“å¼€æµè§ˆå™¨è®¿é—® https://www.bilibili.com
                2. ç™»å½•æ‚¨çš„è´¦å·
                3. æŒ‰F12æ‰“å¼€å¼€å‘è€…å·¥å…· â†’ Application â†’ Cookies
                4. å¤åˆ¶æ‰€æœ‰Cookieå†…å®¹åˆ°æ–‡æœ¬æ–‡ä»¶
                5. ä¸Šä¼ è¯¥æ–‡ä»¶
                """
            )
            
            uploaded_file = st.file_uploader(
                "ä¸Šä¼ Cookieæ–‡ä»¶",
                type=["txt"],
                help="ä¸Šä¼ ä»æµè§ˆå™¨å¯¼å‡ºçš„Cookieæ–‡ä»¶"
            )
            
            if uploaded_file is not None:
                cookies_content = uploaded_file.read().decode('utf-8')
                bilibili_cookies_file = "temp_cookies.txt"
                with open(bilibili_cookies_file, 'w', encoding='utf-8') as f:
                    f.write(cookies_content)
                st.success("âœ… Cookieæ–‡ä»¶å·²åŠ è½½")
            else:
                st.warning("âš ï¸ æœªä¸Šä¼ Cookieæ–‡ä»¶ï¼Œå¯èƒ½å¯¼è‡´é€Ÿç‡é™åˆ¶é”™è¯¯")
        
        st.divider()
        
        st.markdown("""
        ### ğŸ“Œ ä½¿ç”¨è¯´æ˜
        
        **Niconico:**
        - è¾“å…¥æ ¼å¼: `https://www.nicovideo.jp/watch/sm500873`
        - æˆ–: `https://www.video.nicovideo.jp/watch/sm500873` (ä¼šè‡ªåŠ¨è½¬æ¢)
        
        **Bilibili:**
        - è¾“å…¥æ ¼å¼: `https://www.bilibili.com/video/BV1xx411c7mD`
        - æˆ–: `https://www.bilibili.com/video/av123456789`
        - å»ºè®®ä¸Šä¼ Cookieæ–‡ä»¶ä»¥é¿å…é€Ÿç‡é™åˆ¶
        """)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader(f"è¾“å…¥{platform}è§†é¢‘é“¾æ¥")
        video_url = st.text_input(
            "è§†é¢‘é“¾æ¥",
            placeholder=f"è¯·è¾“å…¥{platform}è§†é¢‘é“¾æ¥...",
            label_visibility="collapsed"
        )
    
    with col2:
        st.subheader("æ“ä½œ")
        scrape_button = st.button(
            "ğŸ” å¼€å§‹æŠ“å–",
            use_container_width=True,
            type="primary"
        )
    
    st.divider()
    
    if scrape_button:
        if not video_url.strip():
            st.error("âŒ è¯·è¾“å…¥è§†é¢‘é“¾æ¥")
        else:
            if platform == "Niconico":
                df, video_id = scrape_niconico_danmaku(video_url)
            else:
                df, video_id = scrape_bilibili_danmaku(video_url, cookies_file=bilibili_cookies_file)
            
            if df is not None and len(df) > 0:
                st.success(f"âœ… æˆåŠŸæŠ“å– {len(df)} æ¡å¼¹å¹•ï¼")
                
                st.subheader("ğŸ“Š å¼¹å¹•æ•°æ®é¢„è§ˆ")
                st.dataframe(df, use_container_width=True, height=400)
                
                st.subheader("ğŸ’¾ å¯¼å‡ºé€‰é¡¹")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    excel_buffer = pd.ExcelWriter(
                        f"danmaku_{video_id}.xlsx",
                        engine='openpyxl'
                    )
                    df.to_excel(excel_buffer, index=False, sheet_name='å¼¹å¹•æ•°æ®')
                    excel_buffer.close()
                    
                    with open(f"danmaku_{video_id}.xlsx", 'rb') as f:
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½ Excel",
                            data=f.read(),
                            file_name=f"danmaku_{video_id}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            use_container_width=True
                        )
                    
                    try:
                        os.remove(f"danmaku_{video_id}.xlsx")
                    except OSError:
                        pass
                    
                    if bilibili_cookies_file and os.path.exists(bilibili_cookies_file):
                        try:
                            os.remove(bilibili_cookies_file)
                        except OSError:
                            pass
                
                with col2:
                    csv_buffer = df.to_csv(index=False)
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½ CSV",
                        data=csv_buffer,
                        file_name=f"danmaku_{video_id}.csv",
                        mime="text/csv",
                        use_container_width=True
                    )
                
                with col3:
                    json_buffer = df.to_json(orient='records', force_ascii=False)
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½ JSON",
                        data=json_buffer,
                        file_name=f"danmaku_{video_id}.json",
                        mime="application/json",
                        use_container_width=True
                    )
                
                st.subheader("ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("æ€»å¼¹å¹•æ•°", len(df))
                
                with col2:
                    if 'ç”¨æˆ·ID' in df.columns:
                        unique_users = df['ç”¨æˆ·ID'].nunique()
                        st.metric("ç‹¬ç«‹ç”¨æˆ·æ•°", unique_users)
                
                with col3:
                    if 'å¼¹å¹•å†…å®¹' in df.columns:
                        avg_length = df['å¼¹å¹•å†…å®¹'].str.len().mean()
                        st.metric("å¹³å‡å¼¹å¹•é•¿åº¦", f"{avg_length:.1f} å­—ç¬¦")
            
            elif df is not None and len(df) == 0:
                st.warning("âš ï¸ æœªæ‰¾åˆ°å¼¹å¹•æ•°æ®ï¼Œè¯·æ£€æŸ¥è§†é¢‘é“¾æ¥æ˜¯å¦æ­£ç¡®")
            else:
                st.error("âŒ æŠ“å–å¤±è´¥ï¼Œè¯·æ£€æŸ¥è§†é¢‘é“¾æ¥æˆ–ç½‘ç»œè¿æ¥")
    
    st.divider()
    st.markdown("""
    ### ğŸ“– åŠŸèƒ½è¯´æ˜
    
    **Niconicoå¼¹å¹•æŠ“å–ï¼š**
    - æ”¯æŒæ‰€æœ‰Niconicoè§†é¢‘
    - è‡ªåŠ¨æå–å¼¹å¹•æ—¶é—´æˆ³ã€ç”¨æˆ·IDç­‰ä¿¡æ¯
    - æ”¯æŒå¯¼å‡ºExcelã€CSVã€JSONæ ¼å¼
    
    **Bilibiliå¼¹å¹•æŠ“å–ï¼š**
    - æ”¯æŒBVå·å’Œavå·è§†é¢‘
    - æ¨èä½¿ç”¨Cookieè®¤è¯ä»¥é¿å…é€Ÿç‡é™åˆ¶
    - æ”¯æŒå¯¼å‡ºExcelã€CSVã€JSONæ ¼å¼
    
    **æ³¨æ„äº‹é¡¹ï¼š**
    - è¯·ç¡®ä¿å·²å®‰è£…yt-dlpå·¥å…·
    - æŠ“å–å¤§é‡å¼¹å¹•å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´
    - è¯·éµå®ˆå„å¹³å°çš„ä½¿ç”¨æ¡æ¬¾
    """)
