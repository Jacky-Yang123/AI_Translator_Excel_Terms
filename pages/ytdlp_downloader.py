# pages/ytdlp_downloader.py - yt-dlp è§†é¢‘ä¸‹è½½å™¨é¡µé¢

import os
import json
import time
import subprocess
import tempfile
from pathlib import Path
from datetime import datetime
from io import BytesIO

import pandas as pd
import streamlit as st

try:
    from wordcloud import WordCloud
    HAS_WORDCLOUD = True
except ImportError:
    HAS_WORDCLOUD = False

try:
    import matplotlib.pyplot as plt
    HAS_MATPLOTLIB = True
except ImportError:
    HAS_MATPLOTLIB = False

from utils import Utils


def ytdlp_downloader_app():
    """yt-dlp è§†é¢‘ä¸‹è½½å™¨åº”ç”¨"""
    st.title("ğŸ¬ è§†é¢‘å¼¹å¹•è¯„è®ºä¸‹è½½å™¨")
    st.markdown("### ä½¿ç”¨yt-dlpä¸‹è½½è§†é¢‘ã€å¼¹å¹•å’Œè¯„è®º")

    # é…ç½®æ–‡ä»¶è·¯å¾„
    config_file = os.path.join(os.path.expanduser("~"), ".ytdlp_downloader_config.json")
    config = Utils.load_config(config_file)

    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("âš™ï¸ è®¾ç½®")

        save_path = st.text_input(
            "ä¿å­˜è·¯å¾„",
            value=config.get("save_path", os.path.join(os.path.expanduser("~"), "Downloads", "Yt-DLP-Data")),
            key="save_path_input"
        )

        proxy = st.text_input(
            "ä»£ç†è®¾ç½® (å¯é€‰)",
            value=config.get("proxy", ""),
            placeholder="ä¾‹å¦‚: http://127.0.0.1:7890",
            key="proxy_input"
        )

        naming_tmpl = st.text_input(
            "æ–‡ä»¶å‘½åæ¨¡æ¿",
            value=config.get("naming_tmpl", "%(title)s"),
            key="naming_tmpl_input"
        )

        if st.button("ğŸ’¾ ä¿å­˜è®¾ç½®"):
            config["save_path"] = save_path
            config["proxy"] = proxy
            config["naming_tmpl"] = naming_tmpl
            Utils.save_config(config_file, config)
            st.success("âœ… è®¾ç½®å·²ä¿å­˜")

        st.divider()

        if st.button("ğŸ“‚ æ‰“å¼€ä¿å­˜æ–‡ä»¶å¤¹"):
            if os.path.exists(save_path):
                Utils.open_folder(save_path)
            else:
                os.makedirs(save_path, exist_ok=True)
                Utils.open_folder(save_path)

    # ä¸»ç•Œé¢
    st.header("ğŸ“¥ ä¸‹è½½è®¾ç½®")

    video_url = st.text_input(
        "è§†é¢‘é“¾æ¥",
        placeholder="è¯·è¾“å…¥Bilibili/Niconicoè§†é¢‘é“¾æ¥...",
        key="video_url_input"
    )

    col1, col2 = st.columns(2)

    with col1:
        platform = st.selectbox(
            "å¹³å°",
            options=["Bilibili", "Niconico", "YouTube", "å…¶ä»–"],
            key="platform_select"
        )

    with col2:
        download_type = st.multiselect(
            "ä¸‹è½½å†…å®¹",
            options=["è§†é¢‘", "å¼¹å¹•", "è¯„è®º", "å­—å¹•"],
            default=["å¼¹å¹•"],
            key="download_type_select"
        )

    # Cookieè®¾ç½®
    with st.expander("ğŸ” Cookieè®¾ç½®ï¼ˆç™»å½•åå†…å®¹éœ€è¦ï¼‰"):
        cookie_upload = st.file_uploader(
            "ä¸Šä¼ Cookieæ–‡ä»¶",
            type=['txt'],
            key="cookie_uploader"
        )

        cookie_string = st.text_area(
            "æˆ–ç²˜è´´Cookieå­—ç¬¦ä¸²",
            placeholder="SESSDATA=xxx; bili_jct=xxx; ...",
            key="cookie_string_input"
        )

    # ä¸‹è½½æŒ‰é’®
    if st.button("ğŸš€ å¼€å§‹ä¸‹è½½", type="primary", use_container_width=True):
        if not video_url:
            st.error("âŒ è¯·è¾“å…¥è§†é¢‘é“¾æ¥")
            return

        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(save_path, exist_ok=True)

        # å‡†å¤‡Cookieæ–‡ä»¶
        cookies_file = None
        if cookie_upload:
            temp_cookie = tempfile.NamedTemporaryFile(delete=False, suffix='.txt')
            temp_cookie.write(cookie_upload.read())
            temp_cookie.close()
            cookies_file = temp_cookie.name
        elif cookie_string:
            cookies_file = Utils.create_netscape_cookie_file(cookie_string)

        try:
            import yt_dlp

            progress_bar = st.progress(0)
            status_text = st.empty()

            output_template = os.path.join(save_path, f"{naming_tmpl}.%(ext)s")

            ydl_opts = {
                'outtmpl': output_template,
                'quiet': True,
                'no_warnings': True,
            }

            if proxy:
                ydl_opts['proxy'] = proxy

            if cookies_file:
                ydl_opts['cookiefile'] = cookies_file

            # æ ¹æ®ä¸‹è½½ç±»å‹è®¾ç½®é€‰é¡¹
            if "è§†é¢‘" not in download_type:
                ydl_opts['skip_download'] = True

            if "å¼¹å¹•" in download_type or "å­—å¹•" in download_type:
                ydl_opts['writesubtitles'] = True
                ydl_opts['subtitlesformat'] = 'xml'

            if "è¯„è®º" in download_type:
                ydl_opts['getcomments'] = True
                ydl_opts['writeinfojson'] = True

            status_text.text("æ­£åœ¨è·å–è§†é¢‘ä¿¡æ¯...")
            progress_bar.progress(20)

            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                info = ydl.extract_info(video_url, download=True)
                title = info.get('title', 'video')

            progress_bar.progress(80)
            status_text.text("æ­£åœ¨å¤„ç†ä¸‹è½½çš„æ–‡ä»¶...")

            results = []

            # å¤„ç†å¼¹å¹•
            if "å¼¹å¹•" in download_type:
                xml_files = list(Path(save_path).glob(f"*{title}*.xml"))
                for xml_file in xml_files:
                    excel_path = xml_file.with_suffix('.xlsx')
                    success, count = Utils.process_xml_to_excel(str(xml_file), str(excel_path))
                    if success:
                        results.append(f"å¼¹å¹•: {count} æ¡")

            # å¤„ç†è¯„è®º
            if "è¯„è®º" in download_type:
                json_files = list(Path(save_path).glob(f"*{title}*.info.json"))
                for json_file in json_files:
                    excel_path = json_file.with_suffix('.comments.xlsx')
                    success, count = Utils.process_json_to_excel(str(json_file), str(excel_path))
                    if success:
                        results.append(f"è¯„è®º: {count} æ¡")

            progress_bar.progress(100)
            status_text.empty()
            progress_bar.empty()

            if results:
                st.success(f"âœ… ä¸‹è½½å®Œæˆï¼è§†é¢‘: {title}")
                for result in results:
                    st.info(result)
            else:
                st.success(f"âœ… ä¸‹è½½å®Œæˆï¼è§†é¢‘: {title}")

        except ImportError:
            st.error("âŒ è¯·å®‰è£…yt-dlp: pip install yt-dlp")
        except Exception as e:
            st.error(f"âŒ ä¸‹è½½å¤±è´¥: {e}")

    # è¯äº‘ç”Ÿæˆ
    st.header("â˜ï¸ è¯äº‘ç”Ÿæˆ")

    uploaded_excel = st.file_uploader(
        "ä¸Šä¼ å¼¹å¹•/è¯„è®ºExcelæ–‡ä»¶",
        type=['xlsx', 'xls'],
        key="wordcloud_uploader"
    )

    if uploaded_excel:
        try:
            df = pd.read_excel(uploaded_excel)
            st.success(f"âœ… è¯»å–æˆåŠŸ: {len(df)} æ¡æ•°æ®")

            with st.expander("ğŸ“Š æ•°æ®é¢„è§ˆ"):
                st.dataframe(df.head(20))

            text_col = st.selectbox(
                "é€‰æ‹©æ–‡æœ¬åˆ—",
                options=df.columns.tolist(),
                key="text_col_select"
            )

            if st.button("â˜ï¸ ç”Ÿæˆè¯äº‘", use_container_width=True):
                if not HAS_WORDCLOUD:
                    st.error("âŒ è¯·å®‰è£…wordcloud: pip install wordcloud")
                    return

                if not HAS_MATPLOTLIB:
                    st.error("âŒ è¯·å®‰è£…matplotlib: pip install matplotlib")
                    return

                text_list = df[text_col].dropna().astype(str).tolist()
                wc = Utils.generate_wordcloud_img(text_list)

                if wc:
                    fig, ax = plt.subplots(figsize=(10, 5))
                    ax.imshow(wc, interpolation='bilinear')
                    ax.axis('off')
                    st.pyplot(fig)

                    # ä¿å­˜è¯äº‘
                    img_buffer = BytesIO()
                    wc.to_image().save(img_buffer, format='PNG')

                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½è¯äº‘å›¾ç‰‡",
                        data=img_buffer.getvalue(),
                        file_name=f"wordcloud_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png",
                        mime="image/png",
                        use_container_width=True
                    )
                else:
                    st.warning("âš ï¸ æ— æ³•ç”Ÿæˆè¯äº‘ï¼Œè¯·æ£€æŸ¥æ•°æ®")

        except Exception as e:
            st.error(f"âŒ å¤„ç†å¤±è´¥: {e}")
