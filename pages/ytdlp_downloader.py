import os
import glob
import io
import pandas as pd
import streamlit as st
import yt_dlp
from utils import Utils, HAS_WORDCLOUD


def ytdlp_downloader_app():
    """
    Streamlit ä¸»å‡½æ•°ç»„ä»¶ã€‚
    è°ƒç”¨æ­¤å‡½æ•°å³å¯åœ¨ä»»ä½•é¡µé¢æ¸²æŸ“ä¸‹è½½å™¨ã€‚
    """
    
    if 'ytdlp_queue' not in st.session_state: 
        st.session_state.ytdlp_queue = []
    if 'ytdlp_history' not in st.session_state: 
        st.session_state.ytdlp_history = []
    if 'current_meta' not in st.session_state: 
        st.session_state.current_meta = None
    if 'available_formats' not in st.session_state: 
        st.session_state.available_formats = []
    
    CONFIG_FILE = "ytdlp_config.json"
    config = Utils.load_config(CONFIG_FILE)

    st.title("ğŸ“º YT-DLP å…¨èƒ½åª’ä½“ç»ˆç«¯")
    if not HAS_WORDCLOUD:
        st.warning("âš ï¸ æ£€æµ‹åˆ°æœªå®‰è£… wordcloud åº“ï¼Œè¯äº‘åŠŸèƒ½å°†ä¸å¯ç”¨ï¼Œä½†ä¸‹è½½åŠŸèƒ½æ­£å¸¸ã€‚")

    with st.sidebar:
        st.header("âš™ï¸ è®¾ç½®")
        new_path = st.text_input("ğŸ“‚ ä¿å­˜è·¯å¾„", value=config['save_path'])
        if new_path != config['save_path']:
            config['save_path'] = new_path
            Utils.save_config(CONFIG_FILE, config)

        st.divider()
        st.subheader("ğŸª Cookie (VIP/è¯„è®º)")
        raw_cookie = st.text_area("ç²˜è´´ Cookie (SESSDATA=...)", height=100, help="F12æŠ“å–Bç«™è¯·æ±‚å¤´ä¸­çš„Cookie")
        
        temp_cookie_path = None
        if raw_cookie and "SESSDATA" in raw_cookie:
            temp_cookie_path = Utils.create_netscape_cookie_file(raw_cookie)
            if temp_cookie_path: 
                st.success("âœ… Cookie å·²æ¿€æ´»")
        
        st.divider()
        config['proxy'] = st.text_input("ä»£ç† (Proxy)", value=config['proxy'])
        if st.button("ğŸ“‚ æ‰“å¼€æ–‡ä»¶å¤¹"): 
            if os.path.exists(config['save_path']): 
                Utils.open_folder(config['save_path'])

    tab_dl, tab_review = st.tabs(["â¬‡ï¸ ä¸‹è½½ä¸è§£æ", "ğŸ‘ï¸ èµ„äº§ç®¡ç†ä¸è¯äº‘"])

    with tab_dl:
        col1, col2 = st.columns([4,1])
        with col1: 
            url = st.text_input("è§†é¢‘é“¾æ¥", key="url_input")
        with col2: 
            btn_analyze = st.button("ğŸ” è§£æ", use_container_width=True, type="primary")

        def get_opts():
            opts = {'quiet': True, 'proxy': config['proxy'] or None, 'no_warnings': True, 'extractor_args': {'bilibili': {'comment_sort': 'time'}}}
            if temp_cookie_path: 
                opts['cookiefile'] = temp_cookie_path
            return opts

        if btn_analyze and url:
            with st.spinner("æ­£åœ¨è§£ææµ..."):
                try:
                    with yt_dlp.YoutubeDL(get_opts()) as ydl:
                        meta = ydl.extract_info(url, download=False)
                        st.session_state.current_meta = meta
                        formats = meta.get('formats', [])
                        heights = sorted(list(set([f.get('height') for f in formats if f.get('height')])), reverse=True)
                        st.session_state.available_formats = [f"{h}p" for h in heights]
                except Exception as e: 
                    st.error(f"è§£æé”™è¯¯: {e}")

        if st.session_state.current_meta:
            meta = st.session_state.current_meta
            st.divider()
            c1, c2 = st.columns([1, 2])
            with c1: 
                if meta.get('thumbnail'): 
                    st.image(meta['thumbnail'], use_container_width=True)
            with c2:
                st.subheader(meta.get('title'))
                quality = st.selectbox("ç”»è´¨é€‰æ‹©", ["âœ¨ æœ€ä½³ (MP4)"] + st.session_state.available_formats + ["ğŸµ çº¯éŸ³é¢‘"])
                
                cd1, cd2 = st.columns(2)
                with cd1: 
                    get_danmaku = st.checkbox("å¯¼å‡ºå¼¹å¹• Excel", value=True)
                with cd2: 
                    get_comments = st.checkbox("å¯¼å‡ºè¯„è®º Excel", value=True)
                
                limit_cmt = 100
                if get_comments: 
                    limit_cmt = st.slider("è¯„è®ºæŠ“å–é‡", 10, 5000, 500, step=50)

                if st.button("â• åŠ å…¥é˜Ÿåˆ—", type="primary"):
                    st.session_state.ytdlp_queue.append({
                        "url": meta['webpage_url'], "title": meta['title'], "quality": quality,
                        "danmaku": get_danmaku, "comments": get_comments, "limit_cmt": limit_cmt
                    })
                    st.success("å·²åŠ å…¥ä¸‹è½½é˜Ÿåˆ—")

        if st.session_state.ytdlp_queue:
            st.divider()
            if st.button(f"ğŸš€ å¼€å§‹ä¸‹è½½ ({len(st.session_state.ytdlp_queue)} ä¸ªä»»åŠ¡)", type="primary", use_container_width=True):
                prog = st.progress(0)
                for idx, task in enumerate(st.session_state.ytdlp_queue):
                    opts = get_opts()
                    opts.update({'outtmpl': os.path.join(config['save_path'], f"{task['title']}.%(ext)s"), 'ignoreerrors': True, 'merge_output_format': 'mp4', 'writeinfojson': True})
                    
                    if "çº¯éŸ³é¢‘" in task['quality']: 
                        opts['format'] = 'bestaudio/best'
                    elif "æœ€ä½³" in task['quality']: 
                        opts['format'] = 'bestvideo+bestaudio/best'
                    else: 
                        opts['format'] = f"bestvideo[height={task['quality'].replace('p','')}]" + "+bestaudio/best"

                    if task['danmaku']: 
                        opts.update({'writesubtitles': True, 'allsubtitles': True})
                    if task['comments']: 
                        opts.update({'getcomments': True, 'max_comments': task['limit_cmt']})

                    try:
                        with yt_dlp.YoutubeDL(opts) as ydl:
                            ydl.download([task['url']])
                            base = os.path.join(config['save_path'], task['title'])
                            
                            if task['danmaku']:
                                xmls = glob.glob(f"{base}*.xml")
                                if xmls: 
                                    Utils.process_xml_to_excel(xmls[0], f"{base}_å¼¹å¹•.xlsx")
                                    try: 
                                        os.remove(xmls[0])
                                    except: 
                                        pass
                            
                            if task['comments']:
                                json_f = f"{base}.info.json"
                                if os.path.exists(json_f):
                                    Utils.process_json_to_excel(json_f, f"{base}_è¯„è®º.xlsx")
                                    try: 
                                        os.remove(json_f)
                                    except: 
                                        pass

                            st.session_state.ytdlp_history.append({"title": task['title'], "video_path": f"{base}.mp4", "base_name": base})
                    except Exception as e: 
                        st.error(f"ä»»åŠ¡å¤±è´¥: {e}")
                    prog.progress((idx+1)/len(st.session_state.ytdlp_queue))
                
                st.session_state.ytdlp_queue = []
                st.success("å…¨éƒ¨ä»»åŠ¡å®Œæˆï¼")

    with tab_review:
        if not st.session_state.ytdlp_history: 
            st.info("æš‚æ— å†å²è®°å½•")
        
        for item in reversed(st.session_state.ytdlp_history):
            with st.expander(f"ğŸ¥ {item['title']}", expanded=True):
                c_vid, c_data = st.columns([1, 1.5])
                with c_vid:
                    if os.path.exists(item['video_path']): 
                        st.video(item['video_path'])
                    else: 
                        st.warning("æ–‡ä»¶æœªæ‰¾åˆ°")
                
                with c_data:
                    dm_path = f"{item['base_name']}_å¼¹å¹•.xlsx"
                    cm_path = f"{item['base_name']}_è¯„è®º.xlsx"
                    
                    t1, t2 = st.tabs(["ğŸ“Š æ•°æ®", "â˜ï¸ è¯äº‘"])
                    with t1:
                        if os.path.exists(dm_path): 
                            st.dataframe(pd.read_excel(dm_path), height=150)
                        if os.path.exists(cm_path): 
                            st.dataframe(pd.read_excel(cm_path), height=150)
                    
                    with t2:
                        if not HAS_WORDCLOUD:
                            st.error("è¯äº‘åº“ç¼ºå¤±ï¼Œè¯·å®‰è£… wordcloud")
                        else:
                            wc1, wc2 = st.columns(2)
                            with wc1:
                                if os.path.exists(dm_path) and st.button("å¼¹å¹•è¯äº‘", key=f"d_{item['title']}"):
                                    wc = Utils.generate_wordcloud_img(pd.read_excel(dm_path)['å†…å®¹'].tolist())
                                    if wc: 
                                        st.image(wc.to_array(), use_container_width=True)
                                        buf = io.BytesIO()
                                        wc.to_image().save(buf, format='PNG')
                                        st.download_button("ä¸‹è½½", buf.getvalue(), "dm_wc.png", "image/png", key=f"dd_{item['title']}")
                            with wc2:
                                if os.path.exists(cm_path) and st.button("è¯„è®ºè¯äº‘", key=f"c_{item['title']}"):
                                    wc = Utils.generate_wordcloud_img(pd.read_excel(cm_path)['å†…å®¹'].tolist())
                                    if wc: 
                                        st.image(wc.to_array(), use_container_width=True)
                                        buf = io.BytesIO()
                                        wc.to_image().save(buf, format='PNG')
                                        st.download_button("ä¸‹è½½", buf.getvalue(), "cm_wc.png", "image/png", key=f"dc_{item['title']}")
