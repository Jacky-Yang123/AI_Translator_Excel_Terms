# pages/profile_analysis.py - æ–‡çŒ®ç»¼è¿°åˆ†æå·¥å…·
import streamlit as st
import os
import glob
import json
import requests
from docx import Document
import openpyxl
import tempfile
import shutil
from pathlib import Path
import fitz  # PyMuPDF
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
from datetime import datetime
import pandas as pd
import io

# --- 1. æ ¸å¿ƒé€»è¾‘å‡½æ•° (ç§»æ¤è‡ªåŸ 123.py) ---

API_CONFIGS = {
    "DeepSeek": {
        "url": "https://api.deepseek.com/v1/chat/completions",
        "models": ["deepseek-chat", "deepseek-coder", "deepseek-reasoner"],
        "default_model": "deepseek-chat",
        "headers": {"Content-Type": "application/json"}
    },
    "OpenAI": {
        "url": "https://api.openai.com/v1/chat/completions",
        "models": ["gpt-4", "gpt-4-turbo", "gpt-3.5-turbo", "gpt-3.5-turbo-16k"],
        "default_model": "gpt-3.5-turbo",
        "headers": {"Content-Type": "application/json"}
    },
    "New API (DeepSeek-v3)": {
        "url": "https://tb.api.mkeai.com/v1/chat/completions",
        "models": ["deepseek-v3", "deepseek-v2", "deepseek-v1"],
        "default_model": "deepseek-v3",
        "headers": {"Content-Type": "application/json"}
    }
}

CONFIG_FILE = "api_config_profile.json" # é¿å…ä¸ä¸»é…ç½®å†²çª

def load_config():
    """åŠ è½½ä¿å­˜çš„é…ç½®"""
    if os.path.exists(CONFIG_FILE):
        try:
            with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            pass
    return {}

def save_config(api_provider, api_key, custom_url, model, custom_models, custom_prompt, max_workers, max_retries):
    """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
    try:
        config = {
            "api_provider": api_provider,
            "api_key": api_key,
            "custom_url": custom_url,
            "model": model,
            "custom_models": custom_models,
            "custom_prompt": custom_prompt,
            "max_workers": max_workers,
            "max_retries": max_retries,
            "last_used": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        return False

def read_word_file(file_path):
    """è¯»å–Wordæ–‡æ¡£å†…å®¹"""
    try:
        doc = Document(file_path)
        full_text = []
        for paragraph in doc.paragraphs:
            full_text.append(paragraph.text)
        return '\n'.join(full_text)
    except Exception as e:
        return f"è¯»å–Wordæ–‡ä»¶æ—¶å‡ºé”™: {e}"

def read_pdf_file(file_path):
    """è¯»å–PDFæ–‡æ¡£å†…å®¹ - ä½¿ç”¨PyMuPDF"""
    try:
        doc = fitz.open(file_path)
        full_text = []
        for page_num in range(doc.page_count):
            page = doc.load_page(page_num)
            text = page.get_text()
            full_text.append(text)
        doc.close()
        return '\n'.join(full_text)
    except Exception as e:
        return f"è¯»å–PDFæ–‡ä»¶æ—¶å‡ºé”™: {e}"

def get_file_content(file_path):
    """æ ¹æ®æ–‡ä»¶ç±»å‹è¯»å–å†…å®¹"""
    file_ext = Path(file_path).suffix.lower()
    if file_ext == '.docx':
        return read_word_file(file_path)
    elif file_ext == '.pdf':
        return read_pdf_file(file_path)
    else:
        return f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_ext}"

def call_ai_api(content, api_provider, api_key, custom_url=None, model=None, custom_prompt=""):
    """è°ƒç”¨AI APIåˆ†ææ–‡æ¡£å†…å®¹"""
    if api_provider == "Custom" and custom_url:
        config = {
            "url": custom_url,
            "model": model or "gpt-3.5-turbo",
            "headers": {"Content-Type": "application/json"}
        }
    else:
        config = API_CONFIGS.get(api_provider, API_CONFIGS["DeepSeek"]).copy()
        if model:
            config["model"] = model
        else:
            config["model"] = config.get("default_model", config["models"][0])

    url = config["url"]
    model_name = config["model"]
    headers = config["headers"].copy()
    headers["Authorization"] = f"Bearer {api_key}"

    base_prompt = """è¯·åˆ†æä»¥ä¸‹å­¦æœ¯æ–‡æ¡£ï¼Œä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¿”å›JSONæ•°æ®ï¼š
{
    "title": "æ–‡ç« é¢˜ç›®",
    "authors": "ä½œè€…ä¿¡æ¯", 
    "research_content": "ç ”ç©¶å†…å®¹ï¼ˆ200-300å­—ï¼Œè¯¦ç»†æè¿°ç ”ç©¶çš„é—®é¢˜ã€æ–¹æ³•ã€ç†è®ºæ¡†æ¶ç­‰ï¼‰",
    "research_results": "ç ”ç©¶ç»“æœï¼ˆ200-300å­—ï¼Œè¯¦ç»†æè¿°ä¸»è¦å‘ç°ã€ç»“è®ºã€è´¡çŒ®ç­‰ï¼‰"
}"""

    if custom_prompt.strip():
        full_prompt = f"{base_prompt}\n\né¢å¤–è¦æ±‚ï¼ˆç”¨æˆ·è‡ªå®šä¹‰ï¼‰ï¼š{custom_prompt}\n\næ–‡æ¡£å†…å®¹ï¼š"
    else:
        full_prompt = f"{base_prompt}\n\næ–‡æ¡£å†…å®¹ï¼š"

    prompt = f"{full_prompt}\n{content[:12000]}"

    data = {
        "model": model_name,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.3
    }

    response = requests.post(url, headers=headers, json=data, timeout=120)
    response.raise_for_status()
    result = response.json()
    return result["choices"][0]["message"]["content"]

def parse_api_response(response_text):
    """è§£æAPIè¿”å›çš„JSONæ•°æ®"""
    try:
        start_idx = response_text.find('{')
        end_idx = response_text.rfind('}') + 1
        if start_idx != -1 and end_idx != 0:
            json_str = response_text[start_idx:end_idx]
            return json.loads(json_str)
        else:
            return {"error": "æœªæ‰¾åˆ°æœ‰æ•ˆçš„JSONæ•°æ®"}
    except Exception as e:
        return {"error": f"è§£æAPIå“åº”å¤±è´¥: {e}"}

def process_single_file(file_path, api_provider, api_key, custom_url, model, custom_prompt, max_retries):
    """å¤„ç†å•ä¸ªæ–‡ä»¶"""
    filename = os.path.basename(file_path)
    retry_count = 0
    
    while retry_count <= max_retries:
        if st.session_state.get('stop_processing', False):
             return {
                "status": "stopped",
                "filename": filename,
                "error": "ç”¨æˆ·æ‰‹åŠ¨ç»ˆæ­¢",
                "retry_count": retry_count
            }

        try:
            content = get_file_content(file_path)
            if content.startswith("è¯»å–æ–‡ä»¶æ—¶å‡ºé”™") or content.startswith("ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹"):
                return {
                    "status": "failed",
                    "filename": filename,
                    "error": content,
                    "retry_count": retry_count
                }

            api_response = call_ai_api(content, api_provider, api_key, custom_url, model, custom_prompt)
            
            parsed_data = parse_api_response(api_response)
            if "error" in parsed_data:
                raise Exception(parsed_data["error"])
            
            parsed_data["filename"] = filename
            parsed_data["retry_count"] = retry_count
            return {
                "status": "success",
                "data": parsed_data,
                "filename": filename,
                "retry_count": retry_count
            }
            
        except Exception as e:
            retry_count += 1
            if retry_count <= max_retries:
                 if st.session_state.get('stop_processing', False):
                     return {
                        "status": "stopped",
                        "filename": filename,
                        "error": "ç”¨æˆ·æ‰‹åŠ¨ç»ˆæ­¢",
                        "retry_count": retry_count - 1
                    }
                 time.sleep(2 ** retry_count) # Backoff
            else:
                return {
                    "status": "failed",
                    "filename": filename,
                    "error": str(e),
                    "retry_count": retry_count - 1
                }

# --- 2. é¡µé¢ä¸»å‡½æ•° ---

def profile_analysis_page():
    st.title("ğŸ“‘ æ–‡çŒ®ç»¼è¿°åˆ†æå·¥å…·")
    st.caption("ğŸ“š æ”¯æŒå¤šçº¿ç¨‹å¤„ç† | å®æ—¶é¢„è§ˆ | è‡ªåŠ¨é‡è¯• | ç»“æœå¯¼å‡º")
    
    if "pa_logs" not in st.session_state:
        st.session_state.pa_logs = []
    if "pa_results" not in st.session_state:
        st.session_state.pa_results = []
    
    saved_config = load_config()
    
    # --- å·¦ä¾§é…ç½®æ  ---
    with st.sidebar:
        st.header("1. API é…ç½®")
        api_provider = st.selectbox(
            "APIæä¾›å•†",
            ["DeepSeek", "OpenAI", "New API (DeepSeek-v3)", "Custom"],
            index=["DeepSeek", "OpenAI", "New API (DeepSeek-v3)", "Custom"].index(saved_config.get("api_provider", "DeepSeek")),
            key="pa_api_provider"
        )
        
        api_key = st.text_input("API å¯†é’¥", type="password", value=saved_config.get("api_key", ""), key="pa_api_key")
        
        custom_url = ""
        custom_models = ""
        if api_provider == "Custom":
            custom_url = st.text_input("è‡ªå®šä¹‰APIåœ°å€", value=saved_config.get("custom_url", ""), key="pa_custom_url")
            model_options = ["gpt-3.5-turbo"] # Default
            current_model = saved_config.get("model", "gpt-3.5-turbo")
            allow_custom_model = True
        else:
            config = API_CONFIGS.get(api_provider)
            model_options = config["models"]
            current_model = saved_config.get("model", config["default_model"])
            allow_custom_model = True 
            
        model = st.selectbox(
            "æ¨¡å‹é€‰æ‹©", 
            model_options + [current_model] if current_model not in model_options else model_options,
            index=model_options.index(current_model) if current_model in model_options else 0,
            key="pa_model"
        )
        if allow_custom_model and api_provider != "Custom": # Allow manual input override logic if needed, simplify for now
             pass 

        st.divider()
        st.header("2. æ€§èƒ½é…ç½®")
        max_workers = st.slider("å¹¶å‘çº¿ç¨‹æ•°", 1, 10, saved_config.get("max_workers", 3), key="pa_workers")
        max_retries = st.number_input("æœ€å¤§é‡è¯•æ¬¡æ•°", 0, 10, saved_config.get("max_retries", 3), key="pa_retries")
        
        st.divider()
        st.header("3. è‡ªå®šä¹‰è¦æ±‚")
        custom_prompt = st.text_area("é¢å¤–åˆ†ææŒ‡ä»¤", value=saved_config.get("custom_prompt", ""), placeholder="ä¾‹å¦‚ï¼šé‡ç‚¹å…³æ³¨å®éªŒæ•°æ®...", key="pa_prompt")
        
        if st.button("ğŸ’¾ ä¿å­˜é…ç½®"):
            save_config(api_provider, api_key, custom_url, model, "", custom_prompt, max_workers, max_retries)
            st.success("é…ç½®å·²ä¿å­˜")
            
    # --- ä¸»æ“ä½œåŒº ---
    
    st.subheader("ğŸ“ æ–‡ä»¶ä¸Šä¼ ")
    input_type = st.radio("å¤„ç†æ–¹å¼", ["å•ä¸ªæ–‡ä»¶ä¸Šä¼ ", "æ–‡ä»¶å¤¹æ‰¹é‡å¤„ç†"], horizontal=True, key="pa_input_type")
    
    files_to_process = []
    temp_dir = None
    
    if input_type == "å•ä¸ªæ–‡ä»¶ä¸Šä¼ ":
        uploaded_files = st.file_uploader("é€‰æ‹©æ–‡æ¡£ (PDF/Word)", type=["docx", "pdf"], accept_multiple_files=True, key="pa_uploader")
        if uploaded_files:
             # Create temp dir and save files
             temp_dir = tempfile.mkdtemp()
             for uploaded_file in uploaded_files:
                 path = os.path.join(temp_dir, uploaded_file.name)
                 with open(path, "wb") as f:
                     f.write(uploaded_file.getbuffer())
                 files_to_process.append(path)
                 
    else:
        folder_path = st.text_input("æœ¬åœ°æ–‡ä»¶å¤¹è·¯å¾„", key="pa_folder_path")
        if folder_path and os.path.exists(folder_path):
             word_files = glob.glob(os.path.join(folder_path, "*.docx"))
             pdf_files = glob.glob(os.path.join(folder_path, "*.pdf"))
             files_to_process = word_files + pdf_files
             if not files_to_process:
                 st.warning("è¯¥æ–‡ä»¶å¤¹ä¸‹æ²¡æœ‰æ‰¾åˆ°æ”¯æŒçš„æ–‡æ¡£ (docx/pdf)")
        elif folder_path:
             st.error("æ–‡ä»¶å¤¹ä¸å­˜åœ¨")
    
    col_start, col_stop = st.columns([1, 1])
    with col_start:
        start_btn = st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary", use_container_width=True, disabled=not files_to_process)
    with col_stop:
        stop_btn = st.button("â¸ï¸ åœæ­¢", type="secondary", use_container_width=True)
        if stop_btn:
            st.session_state.stop_processing = True

    # --- æ‰§è¡Œé€»è¾‘ ---
    if start_btn and files_to_process:
        if not api_key:
            st.error("è¯·å…ˆé…ç½® API Key")
            return
            
        st.session_state.stop_processing = False
        st.session_state.pa_results = []
        st.session_state.pa_logs = []
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        log_container = st.empty()
        
        total_files = len(files_to_process)
        completed = 0
        success = 0
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_file = {executor.submit(
                process_single_file, 
                f, api_provider, api_key, custom_url, model, custom_prompt, max_retries
            ): f for f in files_to_process}
            
            for future in concurrent.futures.as_completed(future_to_file):
                if st.session_state.get('stop_processing', False):
                    st.warning("âš ï¸ å¤„ç†å·²åœæ­¢")
                    executor.shutdown(wait=False)
                    break
                
                f_path = future_to_file[future]
                f_name = os.path.basename(f_path)
                
                try:
                    result = future.result()
                    
                    if result["status"] == "success":
                        st.session_state.pa_results.append(result["data"])
                        success += 1
                        log_msg = f"âœ… æˆåŠŸ: {f_name}"
                        if result["retry_count"] > 0: log_msg += f" (é‡è¯•{result['retry_count']}æ¬¡)"
                    elif result["status"] == "stopped":
                         log_msg = f"â¸ï¸ åœæ­¢: {f_name}"
                    else:
                        log_msg = f"âŒ å¤±è´¥: {f_name} - {result['error']}"
                        
                    st.session_state.pa_logs.append(log_msg)
                    
                except Exception as e:
                     st.session_state.pa_logs.append(f"âŒ å¼‚å¸¸: {f_name} - {str(e)}")
                
                completed += 1
                progress_bar.progress(completed / total_files)
                status_text.text(f"è¿›åº¦: {completed}/{total_files} | æˆåŠŸ: {success}")
                log_container.code("\n".join(st.session_state.pa_logs[-10:])) # Show last 10 logs

        # Clean up temp dir if created
        if temp_dir and os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
            
        if completed == total_files:
            st.success("ğŸ‰ æ‰€æœ‰ä»»åŠ¡å¤„ç†å®Œæˆï¼")
            
    # --- ç»“æœå±•ç¤º & ä¸‹è½½ ---
    if st.session_state.pa_results:
        st.divider()
        st.subheader("ğŸ“Š åˆ†æç»“æœ")
        
        df_results = pd.DataFrame(st.session_state.pa_results)
        
        # æ˜¾ç¤ºé¢„è§ˆ (åªæ˜¾ç¤ºå…³é”®åˆ—)
        display_cols = ["filename", "title", "authors", "research_results"]
        # Ensure cols exist
        display_cols = [c for c in display_cols if c in df_results.columns]
        
        st.dataframe(df_results[display_cols], use_container_width=True)
        
        # Download
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df_results.to_excel(writer, index=False)
        
        st.download_button(
            "ğŸ“¥ ä¸‹è½½å®Œæ•´ Excel æŠ¥å‘Š",
            data=output.getvalue(),
            file_name=f"literature_review_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            type="primary"
        )
